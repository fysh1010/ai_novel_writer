#!/usr/bin/env python3
"""
ç¬¬äº”å±‚ï¼šæ™ºå›Šä½“ï¼ˆCompliance Advisorï¼‰
è´Ÿè´£å†…å®¹å®¡æŸ¥ã€è¿ç¦è¯æ£€æµ‹ã€åŒä¹‰è¯æ›¿æ¢ç­‰åˆè§„æ€§æ£€æŸ¥
"""

import json
import re
from typing import Dict, List, Any, Tuple
from .base_agent import BaseAgent

class ComplianceAdvisorAgent(BaseAgent):
    """æ™ºå›Šä½“ - å†…å®¹å®¡æŸ¥ä¸ä¿®æ­£æ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__("æ™ºå›Šä½“")
        self.sensitive_dict = self._load_sensitive_dict()
        self.replacement_rules = self._load_replacement_rules()
    
    def _load_sensitive_dict(self) -> Dict[str, List[str]]:
        """åŠ è½½æ•æ„Ÿè¯è¯å…¸"""
        import os
        sensitive_dict_file = os.path.join(os.path.dirname(__file__), "..", "data", "sensitive_dict.json")
        
        if os.path.exists(sensitive_dict_file):
            try:
                with open(sensitive_dict_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯å…¸
        return {
            "brands": [
                "è‹¹æœå…¬å¸", "Apple", "iPhone", "iPad", "MacBook",
                "åä¸º", "Huawei", "å°ç±³", "Xiaomi", "OPPO", "VIVO",
                "è…¾è®¯", "Tencent", "é˜¿é‡Œå·´å·´", "Alibaba", "ç™¾åº¦", "Baidu",
                "å­—èŠ‚è·³åŠ¨", "ByteDance", "ç¾å›¢", "Meituan", "æ»´æ»´", "Didi"
            ],
            "political": [
                "æ”¿åºœ", "å›½å®¶", "æ”¿æ²»", "é¢†å¯¼äºº", "ä¸»å¸­", "æ€»ç†",
                "å…±äº§å…š", "ç¤¾ä¼šä¸»ä¹‰", "èµ„æœ¬ä¸»ä¹‰", "æ°‘ä¸»", "è‡ªç”±"
            ],
            "violence": [
                "æš´åŠ›", "è¡€è…¥", "æ€æˆ®", "å± æ€", "æ­»äº¡", "è‡ªæ€",
                "ææ€–", "ææ€–ä¸»ä¹‰", "çˆ†ç‚¸", "æªå‡»", "åˆ€ä¼¤"
            ],
            "adult": [
                "è‰²æƒ…", "æ€§çˆ±", "è£¸ä½“", "æ·«ç§½", "é»„è‰²", "æˆäºº"
            ]
        }
    
    def _load_replacement_rules(self) -> Dict[str, str]:
        """åŠ è½½æ›¿æ¢è§„åˆ™"""
        import os
        replacement_rules_file = os.path.join(os.path.dirname(__file__), "..", "data", "replacement_rules.json")
        
        if os.path.exists(replacement_rules_file):
            try:
                with open(replacement_rules_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                    # åˆå¹¶æ‰€æœ‰ç±»åˆ«çš„æ›¿æ¢è§„åˆ™
                    combined_rules = {}
                    for category, rules in rules_data.items():
                        combined_rules.update(rules)
                    return combined_rules
            except:
                pass
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
        return {
            # å“ç‰Œæ›¿æ¢
            "è‹¹æœå…¬å¸": "æ°´æœç§‘æŠ€",
            "Apple": "æ°´æœç§‘æŠ€",
            "iPhone": "æ™ºèƒ½çµæœº",
            "iPad": "å¹³æ¿çµæœº",
            "MacBook": "ç¬”è®°æœ¬çµæœº",
            "åä¸º": "ç¥å¨ç§‘æŠ€",
            "Huawei": "ç¥å¨ç§‘æŠ€",
            "å°ç±³": "è°·ç‰©ç§‘æŠ€",
            "Xiaomi": "è°·ç‰©ç§‘æŠ€",
            "è…¾è®¯": "å¤©è®¯ç§‘æŠ€",
            "Tencent": "å¤©è®¯ç§‘æŠ€",
            "é˜¿é‡Œå·´å·´": "å¤©å®é›†å›¢",
            "Alibaba": "å¤©å®é›†å›¢",
            "ç™¾åº¦": "åƒåº¦æœç´¢",
            "Baidu": "åƒåº¦æœç´¢",
            "å­—èŠ‚è·³åŠ¨": "å­—èŠ‚ç§‘æŠ€",
            "ByteDance": "å­—èŠ‚ç§‘æŠ€",
            "ç¾å›¢": "ç¾é£Ÿå›¢",
            "Meituan": "ç¾é£Ÿå›¢",
            "æ»´æ»´": "å‡ºè¡Œç§‘æŠ€",
            "Didi": "å‡ºè¡Œç§‘æŠ€",
            
            # æ”¿æ²»æ•æ„Ÿè¯æ›¿æ¢
            "æ”¿åºœ": "ç®¡ç†æœºæ„",
            "å›½å®¶": "åœ°åŒº",
            "æ”¿æ²»": "ç®¡ç†",
            "é¢†å¯¼äºº": "ç®¡ç†è€…",
            "ä¸»å¸­": "è´Ÿè´£äºº",
            "æ€»ç†": "æ‰§è¡Œé•¿",
            "å…±äº§å…š": "ç®¡ç†å…š",
            "ç¤¾ä¼šä¸»ä¹‰": "é›†ä½“ä¸»ä¹‰",
            "èµ„æœ¬ä¸»ä¹‰": "å¸‚åœºä¸»ä¹‰",
            "æ°‘ä¸»": "æ°‘æ²»",
            "è‡ªç”±": "è‡ªä¸»",
            
            # æš´åŠ›è¯æ±‡æ›¿æ¢
            "æš´åŠ›": "å†²çª",
            "è¡€è…¥": "æ¿€çƒˆ",
            "æ€æˆ®": "æˆ˜æ–—",
            "å± æ€": "å¤§è§„æ¨¡æˆ˜æ–—",
            "æ­»äº¡": "ç¦»å»",
            "è‡ªæ€": "è‡ªæˆ‘äº†æ–­",
            "ææ€–": "å¯æ€•",
            "ææ€–ä¸»ä¹‰": "æç«¯ä¸»ä¹‰",
            "çˆ†ç‚¸": "å·¨å“",
            "æªå‡»": "å°„å‡»",
            "åˆ€ä¼¤": "åˆ€ä¼¤",
            
            # æˆäººå†…å®¹æ›¿æ¢
            "è‰²æƒ…": "æƒ…æ„Ÿ",
            "æ€§çˆ±": "äº²å¯†",
            "è£¸ä½“": "æ— è¡£",
            "æ·«ç§½": "ä¸å½“",
            "é»„è‰²": "æˆäºº",
            "æˆäºº": "æˆç†Ÿ"
        }
    
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å†…å®¹å®¡æŸ¥è¯·æ±‚ - å¢å¼ºç‰ˆ"""
        content = input_data.get("content", "")
        content_type = input_data.get("type", "chapter")
        auto_replace = input_data.get("auto_replace", True)  # æ–°å¢ï¼šæ˜¯å¦è‡ªåŠ¨æ›¿æ¢
        force_check = input_data.get("force_check", False)  # æ–°å¢ï¼šå¼ºåˆ¶æ£€æŸ¥
        
        if not content:
            return {
                "content": "",
                "compliance_report": {
                    "status": "empty",
                    "message": "å†…å®¹ä¸ºç©ºï¼Œæ— éœ€å®¡æŸ¥"
                }
            }
        
        # æ™ºèƒ½è§¦å‘æ£€æŸ¥
        if not force_check and not self._should_trigger_compliance_check(content):
            return {
                "content": content,
                "compliance_report": {
                    "status": "skipped",
                    "message": "å†…å®¹å®‰å…¨ï¼Œè·³è¿‡å®¡æŸ¥",
                    "risk_score": 0,
                    "corrections_applied": 0
                }
            }
        
        # æ‰§è¡Œå†…å®¹å®¡æŸ¥
        compliance_result = self._check_compliance(content)
        
        # æ–°å¢ï¼šæ›¿æ¢ç¡®è®¤æœºåˆ¶
        if not auto_replace and compliance_result["issues"]:
            # æ˜¾ç¤ºéœ€è¦ç¡®è®¤çš„æ›¿æ¢é¡¹
            confirmed_issues = self._confirm_replacements(compliance_result["issues"])
            compliance_result["issues"] = confirmed_issues
        
        # ç”Ÿæˆä¿®æ­£åçš„å†…å®¹
        corrected_content = self._apply_corrections(content, compliance_result["issues"])
        
        # ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š
        compliance_report = self._generate_compliance_report(compliance_result, content, corrected_content)
        
        return {
            "content": corrected_content,
            "compliance_report": compliance_report,
            "original_content": content,
            "corrections_applied": len(compliance_result["issues"])
        }
    
    def _check_compliance(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å®¹åˆè§„æ€§ - äº”ç»´å®¡æŸ¥"""
        issues = []
        sensitive_words_found = []
        
        # 1. æ³•å¾‹ç±»å®¡æŸ¥ - å“ç‰Œå/çœŸå®æœºæ„
        legal_issues = self._check_legal_compliance(content)
        issues.extend(legal_issues)
        
        # 2. ç¤¾ä¼šç±»å®¡æŸ¥ - æ”¿æ²»æ•æ„Ÿè¯é¢˜
        social_issues = self._check_social_compliance(content)
        issues.extend(social_issues)
        
        # 3. é“å¾·ç±»å®¡æŸ¥ - æ€§ã€æš´åŠ›ã€ä¾®è¾±
        moral_issues = self._check_moral_compliance(content)
        issues.extend(moral_issues)
        
        # 4. é€»è¾‘ç±»å®¡æŸ¥ - è®¾å®šçŸ›ç›¾ã€æ—¶åºæ··ä¹±
        logic_issues = self._check_logic_consistency(content)
        issues.extend(logic_issues)
        
        # 5. å®¡ç¾ç±»å®¡æŸ¥ - æ–‡é£çªå˜ã€AIç—•è¿¹
        aesthetic_issues = self._check_aesthetic_compliance(content)
        issues.extend(aesthetic_issues)
        
        # è®¡ç®—é£é™©è¯„åˆ†
        risk_score = self._calculate_risk_score(issues)
        
        # æ–°å¢ï¼šé—®é¢˜åˆ†çº§ä½“ç³»
        classified_issues = self._classify_issues_by_severity(issues)
        
        return {
            "issues": issues,
            "classified_issues": classified_issues,
            "sensitive_words": sensitive_words_found,
            "total_issues": len(issues),
            "high_severity": len([i for i in issues if i.get("severity") == "high"]),
            "medium_severity": len([i for i in issues if i.get("severity") == "medium"]),
            "low_severity": len([i for i in issues if i.get("severity") == "low"]),
            "risk_score": risk_score,
            "dimension_scores": {
                "legal": len(legal_issues),
                "social": len(social_issues),
                "moral": len(moral_issues),
                "logic": len(logic_issues),
                "aesthetic": len(aesthetic_issues)
            }
        }
    
    def _get_severity(self, category: str) -> str:
        """è·å–é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
        severity_map = {
            "political": "high",
            "violence": "high", 
            "adult": "high",
            "brands": "medium"
        }
        return severity_map.get(category, "low")
    
    def _classify_issues_by_severity(self, issues: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """é—®é¢˜åˆ†çº§ä½“ç³» - å¢å¼ºç‰ˆ"""
        classified = {
            "critical": [],  # é«˜å±ï¼šæ”¿æ²»ã€è‰²æƒ…ã€ä»‡æ¨ã€æš´åŠ›
            "warning": [],   # ä¸­å±ï¼šå•†æ ‡ã€å…¬å¸åã€ç¤¾ä¼šæœºæ„
            "suggestion": [] # ä½å±ï¼šæ•æ„Ÿè¡¨è¾¾ã€éšå–»ã€è®½åˆº
        }
        
        for issue in issues:
            severity = issue.get("severity", "medium")
            category = issue.get("category", "")
            
            if severity == "high" or category in ["political", "violence", "adult", "hate"]:
                classified["critical"].append(issue)
            elif severity == "medium" or category in ["brands", "company", "institution"]:
                classified["warning"].append(issue)
            else:
                classified["suggestion"].append(issue)
        
        return classified
    
    def _confirm_replacements(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ›¿æ¢ç¡®è®¤æœºåˆ¶"""
        confirmed_issues = []
        
        for issue in issues:
            if issue.get("type") == "sensitive_word" and issue.get("replacement"):
                original = issue.get("original", "")
                replacement = issue.get("replacement", "")
                category = issue.get("category", "")
                
                print(f"\nğŸ” æ™ºå›Šä½“å‘ç°: \"{original}\" â†’ \"{replacement}\"")
                print(f"   ç±»åˆ«: {category}")
                
                # é«˜å±é—®é¢˜è‡ªåŠ¨æ›¿æ¢ï¼Œå…¶ä»–éœ€è¦ç¡®è®¤
                if issue.get("severity") == "high":
                    print("   âš ï¸ é«˜å±å†…å®¹ï¼Œè‡ªåŠ¨æ›¿æ¢")
                    confirmed_issues.append(issue)
                else:
                    confirm = input("   æ˜¯å¦æ¥å—æ­¤æ›¿æ¢ï¼Ÿ (y/n): ").strip().lower()
                    if confirm == 'y':
                        confirmed_issues.append(issue)
                        print("   âœ… å·²ç¡®è®¤æ›¿æ¢")
                    else:
                        print("   âŒ è·³è¿‡æ›¿æ¢")
            else:
                confirmed_issues.append(issue)
        
        return confirmed_issues
    
    def _generate_summary_report(self, compliance_result: Dict[str, Any], content: str) -> str:
        """è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        total_words = len(content_text)
        total_issues = compliance_result.get("total_issues", 0)
        risk_score = compliance_result.get("risk_score", 0)
        classified_issues = compliance_result.get("classified_issues", {})
        
        critical_count = len(classified_issues.get("critical", []))
        warning_count = len(classified_issues.get("warning", []))
        suggestion_count = len(classified_issues.get("suggestion", []))
        
        # è®¡ç®—å®‰å…¨è¯„åˆ†
        safety_score = max(0, 100 - risk_score)
        
        summary = f"""
ğŸ“‹ æœ¬ç« åˆè§„æ‘˜è¦:
   æ€»è¯æ•°: {total_words:,}
   å‘ç°é—®é¢˜: {total_issues} ä¸ª
   - âŒ é«˜å±: {critical_count} ä¸ª
   - âš ï¸ ä¸­å±: {warning_count} ä¸ª  
   - ğŸ“ ä½å±: {suggestion_count} ä¸ª
   å®‰å…¨è¯„åˆ†: {safety_score}%
   å®¡æŸ¥çŠ¶æ€: {'âœ… é€šè¿‡' if risk_score < 50 else 'âš ï¸ éœ€æ³¨æ„' if risk_score < 80 else 'âŒ é«˜é£é™©'}
"""
        return summary.strip()
    
    def _check_logic_consistency(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§ - å¢å¼ºç‰ˆ"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)

        issues = []

        # 1. åŸºç¡€é€»è¾‘æ£€æŸ¥
        basic_logic_issues = self._check_basic_logic(content_text)
        issues.extend(basic_logic_issues)

        # 2. æƒé™é€»è¾‘æ£€æŸ¥ï¼ˆç¨‹åºå‘˜è§†è§’ï¼‰
        permission_issues = self._check_permission_logic(content_text)
        issues.extend(permission_issues)

        # 3. ç³»ç»Ÿé€»è¾‘æ£€æŸ¥ï¼ˆæŠ€æœ¯è§†è§’ï¼‰
        system_issues = self._check_system_logic(content_text)
        issues.extend(system_issues)

        # 4. è¯»è€…è§†è§’é€»è¾‘æ£€æŸ¥
        reader_issues = self._check_reader_perspective(content_text)
        issues.extend(reader_issues)

        # 5. æ–‡å­¦è´¨é‡æ£€æŸ¥
        literary_issues = self._check_literary_quality(content_text)
        issues.extend(literary_issues)

        return issues
    
    def _check_basic_logic(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥åŸºç¡€é€»è¾‘"""
        issues = []
        
        # æ£€æŸ¥æ—¶é—´é€»è¾‘
        time_patterns = [
            r"(\d{4})å¹´.*?(\d{4})å¹´",
            r"æ˜¨å¤©.*?æ˜å¤©",
            r"ä¸Šå‘¨.*?ä¸‹å‘¨"
        ]
        
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            if matches:
                issues.append({
                    "type": "logic_inconsistency",
                    "category": "time_logic",
                    "description": f"å‘ç°æ—¶é—´é€»è¾‘é—®é¢˜: {matches[0]}",
                    "severity": "medium"
                })
        
        # æ£€æŸ¥äººç‰©é€»è¾‘
        character_patterns = [
            r"(\w+)æ­»äº†.*?(\w+)è¿˜æ´»ç€",
            r"(\w+)æ˜¯(\w+)çš„å„¿å­.*?(\w+)æ˜¯(\w+)çš„çˆ¶äº²"
        ]
        
        for pattern in character_patterns:
            matches = re.findall(pattern, content)
            if matches:
                issues.append({
                    "type": "logic_inconsistency", 
                    "category": "character_logic",
                    "description": f"å‘ç°äººç‰©é€»è¾‘é—®é¢˜: {matches[0]}",
                    "severity": "medium"
                })
        
        return issues
    
    def _check_permission_logic(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æƒé™é€»è¾‘ï¼ˆç¨‹åºå‘˜è§†è§’ï¼‰"""
        issues = []
        
        # æ£€æŸ¥æƒé™çŸ›ç›¾
        if ("åªè¯»æƒé™" in content or "åªè¯»è®¿é—®" in content) and ("ä¿®æ”¹" in content or "å†™å…¥" in content or "ç¼–è¾‘" in content):
            issues.append({
                "type": "permission_contradiction",
                "description": "æƒé™é€»è¾‘çŸ›ç›¾ï¼šåªè¯»æƒé™æ— æ³•è¿›è¡Œä¿®æ”¹æ“ä½œ",
                "severity": "high",
                "category": "logic",
                "suggestion": "éœ€è¦è§£é‡Šæƒé™æ¥æºï¼Œå¦‚'ç³»ç»Ÿæ¼æ´'ã€'ç‰¹æ®Šèº«ä»½'æˆ–'ä¸´æ—¶æƒé™'"
            })
        
        # æ£€æŸ¥æƒé™å‡çº§é€»è¾‘
        if "æƒé™ç­‰çº§" in content and "æå‡" in content:
            if "åŸå› " not in content and "ä¸ºä»€ä¹ˆ" not in content:
                issues.append({
                    "type": "permission_upgrade_unclear",
                    "description": "æƒé™å‡çº§åŸå› ä¸æ˜ç¡®",
                    "severity": "medium",
                    "category": "logic",
                    "suggestion": "éœ€è¦è§£é‡Šæƒé™å‡çº§çš„åŸå› å’Œè¿‡ç¨‹"
                })
        
        return issues
    
    def _check_system_logic(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ç³»ç»Ÿé€»è¾‘ï¼ˆæŠ€æœ¯è§†è§’ï¼‰"""
        issues = []
        
        # æ£€æŸ¥ç³»ç»Ÿbugé€»è¾‘
        if "æœªå®šä¹‰" in content and "ç³»ç»Ÿ" in content:
            if "å®Œå–„" in content or "ç¨³å®š" in content:
                issues.append({
                    "type": "system_logic_contradiction",
                    "description": "ç³»ç»Ÿé€»è¾‘çŸ›ç›¾ï¼šå®Œå–„ç³»ç»Ÿä¸åº”æœ‰æœªå®šä¹‰å€¼",
                    "severity": "high",
                    "category": "logic",
                    "suggestion": "éœ€è¦è§£é‡Šä¸º'ç³»ç»Ÿå‡çº§ä¸­'ã€'æƒé™å˜æ›´'æˆ–'æ£€æµ‹æ¨¡å—æŸå'"
                })
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶é€»è¾‘
        if "é…ç½®æ–‡ä»¶" in content and "ä¿®æ”¹" in content:
            if "æƒé™" not in content and "æˆæƒ" not in content:
                issues.append({
                    "type": "config_edit_permission_unclear",
                    "description": "é…ç½®æ–‡ä»¶ä¿®æ”¹æƒé™ä¸æ˜ç¡®",
                    "severity": "medium",
                    "category": "logic",
                    "suggestion": "éœ€è¦è¯´æ˜ä¸ºä»€ä¹ˆèƒ½ä¿®æ”¹é…ç½®æ–‡ä»¶"
                })
        
        return issues
    
    def _check_reader_perspective(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥è¯»è€…è§†è§’é€»è¾‘"""
        issues = []
        
        # æ£€æŸ¥å¯èƒ½å¼•èµ·è¯»è€…ç–‘é—®çš„åœ°æ–¹
        if "çªç„¶" in content or "å¿½ç„¶" in content:
            if "åŸå› " not in content and "ä¸ºä»€ä¹ˆ" not in content:
                issues.append({
                    "type": "sudden_change_unexplained",
                    "description": "çªç„¶å˜åŒ–ç¼ºä¹è§£é‡Š",
                    "severity": "medium",
                    "category": "logic",
                    "suggestion": "éœ€è¦è§£é‡Šçªç„¶å˜åŒ–çš„åŸå› "
                })
        
        # æ£€æŸ¥å› æœå…³ç³»
        if "å› ä¸º" in content and "æ‰€ä»¥" in content:
            if "ä½†æ˜¯" in content or "ç„¶è€Œ" in content:
                issues.append({
                    "type": "causal_relationship_unclear",
                    "description": "å› æœå…³ç³»å¯èƒ½ä¸æ¸…æ™°",
                    "severity": "low",
                    "category": "logic",
                    "suggestion": "éœ€è¦æ˜ç¡®å› æœå…³ç³»"
                })
        
        return issues
    
    def _check_literary_quality(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ–‡å­¦è´¨é‡"""
        issues = []

        # æ£€æŸ¥æ–‡ç¬”è´¨é‡
        if "ç„¶å" in content and content.count("ç„¶å") > 3:
            issues.append({
                "type": "repetitive_language",
                "description": "è¯­è¨€é‡å¤ï¼Œæ–‡ç¬”å•è°ƒ",
                "severity": "medium",
                "category": "literary",
                "suggestion": "ä½¿ç”¨æ›´å¤šæ ·åŒ–çš„è¿æ¥è¯å’Œè¡¨è¾¾æ–¹å¼"
            })

        # æ£€æŸ¥æƒ…æ„Ÿæ·±åº¦
        if "å¾ˆ" in content and content.count("å¾ˆ") > 5:
            issues.append({
                "type": "shallow_emotion",
                "description": "æƒ…æ„Ÿè¡¨è¾¾è¿‡äºæµ…æ˜¾",
                "severity": "medium",
                "category": "literary",
                "suggestion": "ä½¿ç”¨æ›´æ·±åˆ»çš„æƒ…æ„Ÿè¡¨è¾¾æ–¹å¼"
            })

        # æ£€æŸ¥åˆ›æ„æ€§
        if "çªç„¶" in content and "å¿½ç„¶" in content:
            issues.append({
                "type": "lack_creativity",
                "description": "è¡¨è¾¾æ–¹å¼ç¼ºä¹åˆ›æ„",
                "severity": "low",
                "category": "literary",
                "suggestion": "ä½¿ç”¨æ›´ç‹¬ç‰¹çš„è¡¨è¾¾æ–¹å¼"
            })

        # æ£€æŸ¥æ–‡å­¦ä»·å€¼
        if len(content) < 1000:
            issues.append({
                "type": "insufficient_content",
                "description": "å†…å®¹è¿‡äºç®€çŸ­ï¼Œç¼ºä¹æ–‡å­¦æ·±åº¦",
                "severity": "medium",
                "category": "literary",
                "suggestion": "å¢åŠ å†…å®¹æ·±åº¦å’Œæ–‡å­¦ä»·å€¼"
            })

        return issues
    
    def _check_semantic_ambiguity(self, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥è¯­ä¹‰æ­§ä¹‰"""
        issues = []
        
        # æ£€æŸ¥æ¨¡ç³Šè¡¨è¿°
        ambiguous_patterns = [
            r"å¯èƒ½.*?å¯èƒ½",
            r"ä¹Ÿè®¸.*?ä¹Ÿè®¸", 
            r"å¤§æ¦‚.*?å¤§æ¦‚",
            r"ä¼¼ä¹.*?ä¼¼ä¹"
        ]
        
        for pattern in ambiguous_patterns:
            matches = re.findall(pattern, content)
            if matches:
                issues.append({
                    "type": "semantic_ambiguity",
                    "category": "ambiguous_expression",
                    "description": f"å‘ç°æ¨¡ç³Šè¡¨è¿°: {matches[0]}",
                    "severity": "low"
                })
        
        return issues
    
    def _check_legal_compliance(self, content: str) -> List[Dict[str, Any]]:
        """æ³•å¾‹ç±»å®¡æŸ¥ - å“ç‰Œå/çœŸå®æœºæ„"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        
        issues = []
        for word in self.sensitive_dict["brands"]:
            if word in content_text:
                issues.append({
                    "type": "legal",
                    "category": "brand",
                    "original": word,
                    "replacement": self.replacement_rules.get(word, "è™šæ„å“ç‰Œ"),
                    "position": content_text.find(word),
                    "severity": "medium"
                })
        return issues
    
    def _check_social_compliance(self, content: str) -> List[Dict[str, Any]]:
        """ç¤¾ä¼šç±»å®¡æŸ¥ - æ”¿æ²»æ•æ„Ÿè¯é¢˜"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        
        issues = []
        for word in self.sensitive_dict["political"]:
            if word in content_text:
                issues.append({
                    "type": "social",
                    "category": "political",
                    "original": word,
                    "replacement": self.replacement_rules.get(word, "ç›¸å…³æœºæ„"),
                    "position": content_text.find(word),
                    "severity": "high"
                })
        return issues
    
    def _check_moral_compliance(self, content: str) -> List[Dict[str, Any]]:
        """é“å¾·ç±»å®¡æŸ¥ - æ€§ã€æš´åŠ›ã€ä¾®è¾±"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        
        issues = []
        for word in self.sensitive_dict["violence"] + self.sensitive_dict["adult"]:
            if word in content_text:
                issues.append({
                    "type": "moral",
                    "category": "violence" if word in self.sensitive_dict["violence"] else "adult",
                    "original": word,
                    "replacement": self.replacement_rules.get(word, "é€‚å½“æè¿°"),
                    "position": content_text.find(word),
                    "severity": "high"
                })
        return issues
    
    def _check_aesthetic_compliance(self, content: str) -> List[Dict[str, Any]]:
        """å®¡ç¾ç±»å®¡æŸ¥ - æ–‡é£çªå˜ã€AIç—•è¿¹"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        
        issues = []
        
        # æ£€æµ‹AIç—•è¿¹
        ai_patterns = [
            "æ ¹æ®æˆ‘çš„ç†è§£", "ä½œä¸ºä¸€ä¸ªAI", "æˆ‘æ— æ³•", "æˆ‘ä¸èƒ½",
            "è¯·æ³¨æ„", "éœ€è¦è¯´æ˜çš„æ˜¯", "å€¼å¾—ä¸€æçš„æ˜¯"
        ]
        
        for pattern in ai_patterns:
            if pattern in content_text:
                issues.append({
                    "type": "aesthetic",
                    "category": "ai_trace",
                    "original": pattern,
                    "replacement": "è‡ªç„¶è¡¨è¾¾",
                    "position": content.find(pattern),
                    "severity": "low"
                })
        
        # æ£€æµ‹æ–‡é£çªå˜ï¼ˆç®€å•æ£€æµ‹ï¼‰
        if len(content_text.split('ã€‚')) > 10:  # é•¿æ–‡æœ¬æ‰æ£€æµ‹
            sentences = content_text.split('ã€‚')
            for i, sentence in enumerate(sentences[:-1]):
                if len(sentence) > 50 and len(sentences[i+1]) > 50:
                    # æ£€æµ‹å¥å­é•¿åº¦å·®å¼‚è¿‡å¤§
                    if abs(len(sentence) - len(sentences[i+1])) > 30:
                        issues.append({
                            "type": "aesthetic",
                            "category": "style_inconsistency",
                            "original": f"å¥å­é•¿åº¦å·®å¼‚: {len(sentence)} vs {len(sentences[i+1])}",
                            "replacement": "è°ƒæ•´å¥å­é•¿åº¦",
                            "position": content_text.find(sentence),
                            "severity": "low"
                        })
        
        return issues
    
    def _calculate_risk_score(self, issues: List[Dict[str, Any]]) -> int:
        """è®¡ç®—é£é™©è¯„åˆ† (0-100)"""
        if not issues:
            return 0
        
        score = 0
        for issue in issues:
            severity = issue.get("severity", "low")
            if severity == "high":
                score += 20
            elif severity == "medium":
                score += 10
            else:
                score += 5
        
        return min(score, 100)
    
    def _apply_corrections(self, content: str, issues: List[Dict[str, Any]]) -> str:
        """åº”ç”¨ä¿®æ­£ - æ™ºèƒ½é‡å†™ + è¯æ±‡æ›¿æ¢"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        corrected_content = content_text
        
        # ç»Ÿè®¡é«˜å±é—®é¢˜æ•°é‡
        high_severity_issues = [i for i in issues if i.get("severity") == "high"]
        medium_severity_issues = [i for i in issues if i.get("severity") == "medium"]
        
        self.log(f"å‘ç°é—®é¢˜ï¼šé«˜å± {len(high_severity_issues)} ä¸ªï¼Œä¸­å± {len(medium_severity_issues)} ä¸ª")
        
        # ç­–ç•¥1ï¼šå¦‚æœæœ‰é«˜å±é—®é¢˜æˆ–ä¸­å±é—®é¢˜è¶…è¿‡3ä¸ªï¼Œæ™ºèƒ½é‡å†™æœ‰é—®é¢˜çš„æ®µè½
        if len(high_severity_issues) > 0 or len(medium_severity_issues) > 3:
            self.log("æ£€æµ‹åˆ°ä¸¥é‡é—®é¢˜ï¼Œå¯åŠ¨æ™ºèƒ½é‡å†™...")
            corrected_content = self._intelligent_rewrite(content_text, issues)
        else:
            # ç­–ç•¥2ï¼šä½å±é—®é¢˜ï¼Œä»…åšè¯æ±‡æ›¿æ¢
            self.log("é—®é¢˜è¾ƒè½»ï¼Œè¿›è¡Œè¯æ±‡æ›¿æ¢...")
            for issue in issues:
                if issue["type"] in ["legal", "social", "moral", "aesthetic"]:
                    original = issue.get("original", "")
                    replacement = issue.get("replacement", "")
                    if original and replacement and original != replacement:
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œç²¾ç¡®æ›¿æ¢ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
                        import re
                        corrected_content = re.sub(fr"\b{re.escape(original)}\b", replacement, corrected_content)
            
            # ä¸Šä¸‹æ–‡è¯­ä¹‰ä¼˜åŒ– - å¦‚æœå†…å®¹æœ‰ä¿®æ”¹ï¼Œè¿›è¡Œè¯­ä¹‰æ¶¦è‰²
            if corrected_content != content_text:
                corrected_content = self._contextual_polish(corrected_content)
        
        return corrected_content
    
    def _intelligent_rewrite(self, content: str, issues: List[Dict[str, Any]]) -> str:
        """æ™ºèƒ½é‡å†™ - é’ˆå¯¹æœ‰é—®é¢˜çš„æ®µè½è¿›è¡Œå®Œæ•´é‡å†™"""
        self.log("æ­£åœ¨ä½¿ç”¨LLMæ™ºèƒ½é‡å†™æœ‰é—®é¢˜çš„å†…å®¹...")
        
        # æå–æ‰€æœ‰æœ‰é—®é¢˜çš„åŸæ–‡
        problem_words = [issue.get("original", "") for issue in issues if issue.get("original")]
        problem_descriptions = [f"{issue.get('original', '')}({issue.get('category', '')})" for issue in issues]
        
        rewrite_prompt = f"""
è¯·é‡å†™ä»¥ä¸‹å†…å®¹ï¼Œè§£å†³å…¶ä¸­çš„åˆè§„é—®é¢˜ï¼š

ã€åŸæ–‡å†…å®¹ã€‘
{content}

ã€å‘ç°çš„é—®é¢˜ã€‘
{chr(10).join([f"{i+1}. {desc}" for i, desc in enumerate(problem_descriptions)])}

ã€é‡å†™è¦æ±‚ã€‘
1. **ä¿æŒåŸæ–‡çš„æ ¸å¿ƒæ„æ€å’Œæƒ…èŠ‚å‘å±•**
2. **å®Œå…¨é¿å…ä½¿ç”¨æœ‰é—®é¢˜çš„è¯æ±‡å’Œè¡¨è¿°**
3. **ä½¿ç”¨åˆè§„ã€å®‰å…¨çš„æ›¿ä»£è¡¨è¾¾**
4. **ä¿æŒæ–‡å­¦æ€§å’Œå¯è¯»æ€§**
5. **å†…å®¹é•¿åº¦ä¸åŸæ–‡ç›¸å½“**

ã€å…·ä½“ä¿®æ”¹æŒ‡å¼•ã€‘
- çœŸå®å“ç‰Œå â†’ æ”¹ä¸ºè™šæ„å“ç‰Œæˆ–é€šç”¨ç§°å‘¼
- æ”¿æ²»æ•æ„Ÿè¯ â†’ æ”¹ä¸ºä¸­æ€§è¡¨è¿°
- æš´åŠ›/è‰²æƒ…å†…å®¹ â†’ æ”¹ä¸ºæš—ç¤ºæˆ–æ·¡åŒ–å¤„ç†
- AIç—•è¿¹æ˜æ˜¾ â†’ æ”¹ä¸ºæ›´è‡ªç„¶çš„äººç±»è¡¨è¾¾

è¯·ç›´æ¥è¿”å›é‡å†™åçš„å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜æˆ–æ³¨é‡Šã€‚
"""
        
        try:
            rewrite_response = self.forward(rewrite_prompt)
            if rewrite_response.is_success():
                rewritten_content = rewrite_response.get_content()
                self.log("æ™ºèƒ½é‡å†™å®Œæˆ")
                return rewritten_content
            else:
                self.log("æ™ºèƒ½é‡å†™å¤±è´¥ï¼Œè¿”å›åŸæ–‡")
                return content
        except Exception as e:
            self.log(f"æ™ºèƒ½é‡å†™å‡ºé”™ï¼š{e}ï¼Œè¿”å›åŸæ–‡")
            return content
    
    def _contextual_polish(self, content: str) -> str:
        """ä¸Šä¸‹æ–‡è¯­ä¹‰æ¶¦è‰²"""
        # å®‰å…¨è·å–å†…å®¹æ–‡æœ¬
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        
        try:
            # åˆ†æ®µå¤„ç†ï¼Œé¿å…è¿‡é•¿æ–‡æœ¬
            sentences = content_text.split('ã€‚')
            polished_sentences = []
            
            for sentence in sentences:
                if sentence.strip():
                    # æ£€æŸ¥å¥å­æ˜¯å¦åŒ…å«æ›¿æ¢åçš„è¯æ±‡
                    if any(replacement in sentence for replacement in self.replacement_rules.values()):
                        # ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰æ¶¦è‰²
                        polish_prompt = f"""
è¯·åœ¨ä¸æ”¹å˜åŸæ„çš„æƒ…å†µä¸‹ï¼Œè®©ä»¥ä¸‹å¥å­æ›´è‡ªç„¶æµç•…ï¼š
"{sentence.strip()}ã€‚"

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„ä¸å˜
2. è®©è¯­è¨€æ›´è‡ªç„¶
3. é¿å…ç”Ÿç¡¬çš„æ›¿æ¢ç—•è¿¹
4. åªè¿”å›æ¶¦è‰²åçš„å¥å­ï¼Œä¸è¦å…¶ä»–è¯´æ˜
"""
                        try:
                            polished_response = self.forward(polish_prompt, show_response=False)
                            if polished_response.is_success():
                                polished_sentence = polished_response.get_content()
                                if polished_sentence and len(polished_sentence.strip()) > 0:
                                    polished_sentences.append(polished_sentence.strip())
                                else:
                                    polished_sentences.append(sentence.strip())
                            else:
                                polished_sentences.append(sentence.strip())
                        except:
                            polished_sentences.append(sentence.strip())
                    else:
                        polished_sentences.append(sentence.strip())
            
            return 'ã€‚'.join(polished_sentences) + ('ã€‚' if content.endswith('ã€‚') else '')
        except:
            return content
    
    def _generate_compliance_report(self, compliance_result: Dict[str, Any], 
                                  original_content: str, corrected_content: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ ‡å‡†åŒ–å®¡æŸ¥æŠ¥å‘Š"""
        # æ ‡å‡†åŒ–é—®é¢˜åˆ—è¡¨
        standardized_issues = []
        for issue in compliance_result["issues"]:
            standardized_issue = {
                "type": issue.get("type", "unknown"),
                "original": issue.get("original", issue.get("word", "")),
                "replacement": issue.get("replacement", ""),
                "position": issue.get("position", -1),
                "severity": issue.get("severity", "low"),
                "category": issue.get("category", "unknown"),
                "description": issue.get("description", "")
            }
            standardized_issues.append(standardized_issue)
        
        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        summary_report = self._generate_summary_report(compliance_result, original_content)
        
        return {
            "chapter": "unknown",  # å°†åœ¨ä¸»æ§æ™ºèƒ½ä½“ä¸­è®¾ç½®
            "timestamp": self._get_timestamp(),
            "content_length": len(original_content.get_content() if hasattr(original_content, 'get_content') else str(original_content)),
            "corrections_applied": compliance_result["total_issues"],
            "risk_score": compliance_result.get("risk_score", 0),
            "severity_breakdown": {
                "high": compliance_result["high_severity"],
                "medium": compliance_result["medium_severity"], 
                "low": compliance_result["low_severity"]
            },
            "classified_issues": compliance_result.get("classified_issues", {}),
            "summary_report": summary_report,
            "dimension_scores": compliance_result.get("dimension_scores", {}),
            "issues": standardized_issues,
            "content_changed": original_content != corrected_content,
            "compliance_status": self._determine_compliance_status(compliance_result),
            "recommendations": self._generate_recommendations(compliance_result)
        }
    
    def _determine_compliance_status(self, compliance_result: Dict[str, Any]) -> str:
        """ç¡®å®šåˆè§„çŠ¶æ€"""
        risk_score = compliance_result.get("risk_score", 0)
        high_severity = compliance_result.get("high_severity", 0)
        
        if high_severity > 0 or risk_score > 50:
            return "needs_review"
        elif risk_score > 20:
            return "caution"
        else:
            return "passed"
    
    def _generate_recommendations(self, compliance_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        dimension_scores = compliance_result.get("dimension_scores", {})
        
        if dimension_scores.get("legal", 0) > 0:
            recommendations.append("å»ºè®®å‡å°‘çœŸå®å“ç‰Œåç§°çš„ä½¿ç”¨ï¼Œä½¿ç”¨è™šæ„å“ç‰Œæ›¿ä»£")
        
        if dimension_scores.get("social", 0) > 0:
            recommendations.append("å»ºè®®é¿å…æ¶‰åŠæ”¿æ²»æ•æ„Ÿè¯é¢˜ï¼Œä½¿ç”¨æ›´ä¸­æ€§çš„è¡¨è¿°")
        
        if dimension_scores.get("moral", 0) > 0:
            recommendations.append("å»ºè®®å‡å°‘æš´åŠ›æˆ–æˆäººå†…å®¹æè¿°ï¼Œä½¿ç”¨æ›´æ¸©å’Œçš„è¡¨è¾¾")
        
        if dimension_scores.get("logic", 0) > 0:
            recommendations.append("å»ºè®®æ£€æŸ¥æƒ…èŠ‚é€»è¾‘ä¸€è‡´æ€§ï¼Œé¿å…æ—¶é—´çº¿æˆ–äººç‰©è®¾å®šçŸ›ç›¾")
        
        if dimension_scores.get("aesthetic", 0) > 0:
            recommendations.append("å»ºè®®ä¼˜åŒ–æ–‡é£ä¸€è‡´æ€§ï¼Œå‡å°‘AIç—•è¿¹")
        
        if not recommendations:
            recommendations.append("å†…å®¹è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
        return recommendations
    
    def _should_trigger_compliance_check(self, content: str) -> bool:
        """æ™ºèƒ½è§¦å‘æ£€æŸ¥ - åŸºäºå‘½ä¸­è¯å’Œå†…å®¹ç‰¹å¾"""
        # é«˜é£é™©å…³é”®è¯åˆ—è¡¨
        high_risk_keywords = [
            "å…¬å¸", "ç»„ç»‡", "æ”¿åºœ", "å›½å®¶", "æ”¿æ²»", "é¢†å¯¼äºº", "ä¸»å¸­", "æ€»ç†",
            "æš´åŠ›", "è¡€è…¥", "æ€æˆ®", "æ­»äº¡", "ææ€–", "çˆ†ç‚¸", "æªå‡»",
            "è‰²æƒ…", "æ€§çˆ±", "è£¸ä½“", "æ·«ç§½", "é»„è‰²", "æˆäºº",
            "è‹¹æœ", "åä¸º", "å°ç±³", "è…¾è®¯", "é˜¿é‡Œå·´å·´", "ç™¾åº¦", "å­—èŠ‚è·³åŠ¨"
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜é£é™©å…³é”®è¯
        content_text = content.get_content() if hasattr(content, 'get_content') else str(content)
        content_lower = content_text.lower()
        for keyword in high_risk_keywords:
            if keyword in content_lower:
                return True
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦ï¼ˆçŸ­å†…å®¹å¯èƒ½ä¸éœ€è¦å®¡æŸ¥ï¼‰
        if len(content_text) < 500:
            return False
        
        # æ£€æŸ¥ä¿®æ”¹ç‡ï¼ˆå¦‚æœä¹‹å‰æœ‰å¤§é‡ä¿®æ”¹ï¼Œéœ€è¦é‡æ–°å®¡æŸ¥ï¼‰
        # è¿™é‡Œå¯ä»¥ç»“åˆå†å²æ•°æ®ï¼Œæš‚æ—¶è¿”å›True
        return True
    
    def _calculate_modification_rate(self, original_content: str, modified_content: str) -> float:
        """è®¡ç®—ä¿®æ”¹ç‡"""
        if not original_content:
            return 0.0
        
        # ç®€å•çš„å­—ç¬¦å·®å¼‚è®¡ç®—
        diff_count = 0
        max_len = max(len(original_content), len(modified_content))
        
        for i in range(max_len):
            if i >= len(original_content) or i >= len(modified_content):
                diff_count += 1
            elif original_content[i] != modified_content[i]:
                diff_count += 1
        
        return diff_count / max_len if max_len > 0 else 0.0
    
    def _get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
